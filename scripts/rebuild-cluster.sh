#!/usr/bin/env bash
set -euo pipefail

SCRIPTS="$(cd "$(dirname "$0")" && pwd)"
BASE_DIR="$(dirname "$SCRIPTS")"
export OPENSHIFT_INSTALL_PRESERVE_BOOTSTRAP=true

CLUSTER_YAML="$1"

if [[ -z "${CLUSTER_YAML:-}" || ! -f "$CLUSTER_YAML" ]]; then
  echo "‚ùå Cluster YAML not found: $CLUSTER_YAML"
  exit 1
fi

CLUSTER_NAME=$(yq e '.clusterName' "$CLUSTER_YAML")
INSTALL_DIR="$BASE_DIR/install-configs/$CLUSTER_NAME"

# Load vCenter environment variables
source "$SCRIPTS/load-vcenter-env.sh"

log_step() {
  echo -e "\n‚è± $(date +'%F %T') - $1"
}

log_step "1Ô∏è‚É£ Validating input YAML file..."
echo "‚úÖ Cluster name: $CLUSTER_NAME"
echo "‚úÖ Install directory: $INSTALL_DIR"

log_step "2Ô∏è‚É£ Deleting previous cluster (if exists)..."
"$SCRIPTS/delete-cluster.sh" "$CLUSTER_YAML"

log_step "3Ô∏è‚É£ Cleaning up previous install directory..."
rm -rf "$INSTALL_DIR"
mkdir -p "$INSTALL_DIR"
echo "‚úÖ Directory reset: $INSTALL_DIR"

log_step "4Ô∏è‚É£ Generating install-config.yaml"
"$SCRIPTS/generate-install-config.sh" "$CLUSTER_YAML"

log_step "5Ô∏è‚É£ Running openshift-install to create ignition configs..."
cp "$INSTALL_DIR"/install-config.yaml "$INSTALL_DIR"/install-config.yaml.bak
rm -rf "$INSTALL_DIR"/{*.ign,manifests,openshift}
openshift-install create manifests --dir="$INSTALL_DIR" --log-level=debug
openshift-install create ignition-configs --dir="$INSTALL_DIR" --log-level=debug

log_step "6Ô∏è‚É£ Generating network configurations to fix OVS conflicts..."
echo "üîß Creating NetworkManager configs to override VM template OVS bridges..."
"$SCRIPTS/generate-network-manifests.sh" "$CLUSTER_YAML" "$INSTALL_DIR"

log_step "6.5Ô∏è‚É£ Merging network configs into ignition files..."
echo "üîß Injecting network configurations into individual node ignition files..."
"$SCRIPTS/merge-network-ignition.sh" "$CLUSTER_YAML" "$INSTALL_DIR"

log_step "7Ô∏è‚É£ Deploying VMs with network-corrected ignition configs"
echo "üöÄ Deploying VMs with ignition files that will override OVS configuration..."
"$SCRIPTS/deploy-vms.sh" "$CLUSTER_YAML" "$INSTALL_DIR"

log_step "8Ô∏è‚É£ Monitoring bootstrap progress (wait for completion)"
echo "‚è≥ Waiting for bootstrap to complete..."
echo "üí° This may take 15-30 minutes as nodes override OVS config and initialize OVN-Kubernetes..."

# Set kubeconfig for monitoring
export KUBECONFIG="$INSTALL_DIR/auth/kubeconfig"

# Wait for bootstrap completion with better error handling
BOOTSTRAP_TIMEOUT=3600  # 60 minutes timeout
BOOTSTRAP_START_TIME=$(date +%s)

while true; do
  CURRENT_TIME=$(date +%s)
  ELAPSED_TIME=$((CURRENT_TIME - BOOTSTRAP_START_TIME))
  
  if [[ $ELAPSED_TIME -gt $BOOTSTRAP_TIMEOUT ]]; then
    echo "‚ùå Bootstrap timed out after ${BOOTSTRAP_TIMEOUT} seconds"
    echo "üí° Check cluster logs: openshift-install wait-for bootstrap-complete --dir=$INSTALL_DIR --log-level=debug"
    exit 1
  fi
  
  if openshift-install wait-for bootstrap-complete --dir="$INSTALL_DIR" --log-level=info; then
    echo "‚úÖ Bootstrap completed successfully!"
    break
  else
    echo "‚åõ Still waiting for bootstrap to complete... (elapsed: ${ELAPSED_TIME}s)"
    sleep 30
  fi
done

log_step "9Ô∏è‚É£ Removing bootstrap VM"
echo "üßπ Bootstrap removal is manual in this runbook."
# "$SCRIPTS/cleanup-bootstrap.sh" "$CLUSTER_YAML"

log_step "üîü Waiting for cluster operators to stabilize..."
echo "‚è≥ Waiting for cluster installation to complete..."
if openshift-install wait-for install-complete --dir="$INSTALL_DIR" --log-level=info; then
  echo "‚úÖ Cluster installation completed!"
else
  echo "‚ö†Ô∏è  Installation monitoring failed, but cluster may still be completing..."
fi

log_step "1Ô∏è‚É£1Ô∏è‚É£ Applying taint fix and labels"
echo "üîß Fixing cloud provider taints..."
"$SCRIPTS/fix-cloud-provider-taints.sh"
echo "üè∑Ô∏è  Applying node labels..."
"$SCRIPTS/label-nodes.sh" "$CLUSTER_YAML"

log_step "1Ô∏è‚É£2Ô∏è‚É£ Verifying cluster health"
for i in {1..40}; do
  AVAILABLE=$(oc get clusterversion version -o jsonpath='{.status.conditions[?(@.type=="Available")].status}' || echo "")
  PROGRESSING=$(oc get clusterversion version -o jsonpath='{.status.conditions[?(@.type=="Progressing")].status}' || echo "")
  DEGRADED=$(oc get clusterversion version -o jsonpath='{.status.conditions[?(@.type=="Degraded")].status}' || echo "")
  echo "ClusterVersion: Available=$AVAILABLE Progressing=$PROGRESSING Degraded=$DEGRADED"
  if [[ "$AVAILABLE" == "True" && "$PROGRESSING" == "False" && "$DEGRADED" == "False" ]]; then
    echo "‚úÖ Cluster healthy."
    break
  fi
  echo "‚åõ Operators still settling‚Ä¶ retry $i/40"
  sleep 15
done

echo -e "\nüéâ Cluster rebuild complete!"

log_step "üîê Cluster access information"
KUBEADMIN_PASS_FILE="$INSTALL_DIR/auth/kubeadmin-password"
if [[ -f "$KUBEADMIN_PASS_FILE" ]]; then
  KUBEADMIN_PASS=$(cat "$KUBEADMIN_PASS_FILE")
  echo -e "‚úÖ kubeadmin password: \033[1;33m$KUBEADMIN_PASS\033[0m"
  echo "üåê Console URL: https://console-openshift-console.apps.$CLUSTER_NAME.$(yq e '.baseDomain' "$CLUSTER_YAML")"
  echo "üîê Login via CLI:"
  echo "oc login -u kubeadmin -p $KUBEADMIN_PASS https://api.$CLUSTER_NAME.$(yq e '.baseDomain' "$CLUSTER_YAML"):6443"
  echo ""
  echo "üìä Quick health check commands:"
  echo "  oc get co"
  echo "  oc get nodes"  
  echo "  oc get pods -A | grep -v Running"
else
  echo "‚ö†Ô∏è kubeadmin password not found in $KUBEADMIN_PASS_FILE"
fi

echo ""
echo "üí° If you encounter OVS bridge issues:"
echo "   1. Check: ssh core@master-X 'sudo nmcli con show'"
echo "   2. Expected: No 'br-ex' or 'ovs-*' connections"
echo "   3. Expected: '${INTERFACE_NAME:-ens192}' ethernet connection with static IP"
echo "   4. Check OVN pods: oc get pods -n openshift-ovn-kubernetes"
